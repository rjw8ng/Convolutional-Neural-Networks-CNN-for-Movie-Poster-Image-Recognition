{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fdf6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "from torch.nn.modules import MSELoss, L1Loss\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "from numpy import array, asarray, ndarray, swapaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c396fe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "     ---------------------------------------- 38.2/38.2 MB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\royal\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "050f0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training controls\n",
    "batch_size = 20\n",
    "epochs = 2\n",
    "training_size = 0.7\n",
    "learning_rate = 0.001\n",
    "dropout = [0.3, 0.3, 0.3, 0.3, 0.2, 0.2, 0.2, 0.2, 0.15]\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 268, 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a60bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data holders\n",
    "x_test = []\n",
    "x_train = []\n",
    "y_test= []\n",
    "y_train= []\n",
    "tempY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5064666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdbId', 'Imdb Link', 'Title', 'IMDB Score', 'Genre', 'Poster']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening the dataset\n",
    "dataset = csv.reader(open(\"MovieGenre.csv\",encoding=\"utf8\",errors='replace'), delimiter=\",\")\n",
    "\n",
    "#skipping the header line\n",
    "next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6841320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "files = zf.ZipFile(\"SampleMoviePosters.zip\", 'r')\n",
    "files.extractall()\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e47f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the list of image files in SampleMoviePosters folder\n",
    "flist=glob.glob('SampleMoviePosters/*.jpg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7925eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data from the CSV file\n",
    "for imdbId, Link, Title, Score, Genre, Poster in dataset:\n",
    "    if(Score!=\"\"):\n",
    "        if(len((int(imdbId),float(Score)))==2):\n",
    "            tempY.append((int(imdbId),float(Score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd7305a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the length of training data\n",
    "length=int(len(flist)*training_size)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23551049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data about the images that are available\n",
    "i=0\n",
    "for filename in flist:\n",
    "    name=int(filename.split('\\\\')[-1][:-4])\n",
    "    for z in tempY:\n",
    "        if(z[0]==name):\n",
    "            \n",
    "            img = array(cv2.imread(filename))\n",
    "            img = swapaxes(img, 2,0)\n",
    "            img = swapaxes(img, 2,1)\n",
    "\n",
    "            if(i<length):\n",
    "                x_train.append(img)\n",
    "                y_train.append(z[1])\n",
    "            else:\n",
    "                x_test.append(img)\n",
    "                y_test.append(z[1])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4f12d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data from lists to numpy arrays\n",
    "x_train=asarray(x_train,dtype=float)\n",
    "x_test=asarray(x_test,dtype=float)\n",
    "y_train=asarray(y_train,dtype=float)\n",
    "y_test=asarray(y_test,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bbaf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling down the RGB data\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77e15d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (715, 3, 268, 182)\n",
      "715 train samples\n",
      "303 test samples\n"
     ]
    }
   ],
   "source": [
    "#printing stats about the features\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18137503",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = x_train.shape[0]\n",
    "\n",
    "#x_train=torch.from_numpy(x_train)\n",
    "#x_test=torch.from_numpy(x_test)\n",
    "#y_train=torch.from_numpy(y_train)\n",
    "#y_test=torch.from_numpy(y_test)\n",
    "\n",
    "train = data_utils.TensorDataset(x_train, y_train)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = data_utils.TensorDataset(x_test, y_test)\n",
    "test_loader = data_utils.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c328f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape=(3, img_rows, img_cols)):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3)\n",
    "        self.conv1_drop = nn.Dropout2d(p=dropout[0])\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d(p=dropout[1])\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.conv3_drop = nn.Dropout2d(p=dropout[2])\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=2)\n",
    "        self.conv4_drop = nn.Dropout2d(p=dropout[3])\n",
    "        self.conv5 = nn.Conv2d(64, 32, kernel_size=2)\n",
    "        self.conv5_drop = nn.Dropout2d(p=dropout[4])\n",
    "        self.conv6 = nn.Conv2d(32, 16, kernel_size=2)\n",
    "        self.conv6_drop = nn.Dropout2d(p=dropout[5])\n",
    "        \n",
    "        n_size = self._get_conv_output(input_shape)\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_size, 16)\n",
    "        self.fc1_drop = nn.Dropout(p=dropout[6])\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc2_drop = nn.Dropout(p=dropout[7])\n",
    "        self.fc3 = nn.Linear(16, 8)\n",
    "        self.fc3_drop = nn.Dropout(p=dropout[8])\n",
    "        self.fc4 = nn.Linear(8, 1)\n",
    "        \n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = Variable(torch.rand(bs, *shape))\n",
    "        output_feat = self._forward_features(input)\n",
    "        n_size = output_feat.data.view(bs, -1).size(1)\n",
    "        return n_size\n",
    "        \n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4_drop(self.conv4(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv5_drop(self.conv5(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv6_drop(self.conv6(x)), 2))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4_drop(self.conv4(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv5_drop(self.conv5(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv6_drop(self.conv6(x)), 2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1_drop(self.fc1(x)))\n",
    "        x = F.relu(self.fc2_drop(self.fc2(x)))\n",
    "        x = F.relu(self.fc3_drop(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fffef5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royal\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = MSELoss(size_average=True)\n",
    "human_criterion = L1Loss(size_average=True)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate,\n",
    "            alpha=0.9, eps=1e-08, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b63a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1_drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3_drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv4_drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (conv5): Conv2d(64, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv5_drop): Dropout2d(p=0.2, inplace=False)\n",
      "  (conv6): Conv2d(32, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv6_drop): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=48, out_features=16, bias=True)\n",
      "  (fc1_drop): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (fc2_drop): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3_drop): Dropout(p=0.15, inplace=False)\n",
      "  (fc4): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royal\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\royal\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20992\\3213744309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20992\\3213744309.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     11\u001b[0m         print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} {:.6f}'.format(\n\u001b[0;32m     12\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             100. * batch_idx / len(train_loader), loss.data[0], human_loss.data[0]))\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data).float(), Variable(target).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        human_loss= human_criterion(output, target)\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.data[0], human_loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    print('test')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    human_loss = 0\n",
    "    i = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        i+=1\n",
    "        data, target = Variable(data, volatile=True).float(), Variable(target).float()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss\n",
    "        human_loss += human_criterion(output, target)\n",
    "        if loss==0:\n",
    "            correct+=1\n",
    "\n",
    "    print('\\nTest set: \\nAverage sq_loss: {:.4f} \\nAverage abs_loss: {:.4f} \\nGuessed 100% correct: {:.4f}\\n'.format(test_loss.data[0]/i, human_loss.data[0]/i, correct))\n",
    "\n",
    "model.float()\n",
    "print(model)\n",
    "for epoch in range(0, epochs):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdff5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
